# ü§ñ Integra√ß√£o OpenAI - Guia de Implementa√ß√£o

## üìã Vis√£o Geral

Integra√ß√£o da OpenAI API para gerar roasts musicais mais inteligentes e criativos, mantendo o sistema atual como fallback.

## üîß Implementa√ß√£o Passo a Passo

### **1. Instala√ß√£o e Configura√ß√£o**

```bash
# Instalar depend√™ncia da OpenAI
npm install openai

# Atualizar .env
echo "VITE_OPENAI_API_KEY=sk-your-api-key-here" >> .env
```

### **2. Criar Servi√ßo OpenAI**

```javascript
// src/services/openaiService.js
import OpenAI from 'openai'

class OpenAIRoastService {
  constructor() {
    this.openai = new OpenAI({
      apiKey: import.meta.env.VITE_OPENAI_API_KEY,
      dangerouslyAllowBrowser: true // Para uso em frontend
    })
    this.maxRetries = 2
    this.rateLimitDelay = 1000 // 1 segundo entre requests
  }

  // Construir prompt especializado para cada tom
  buildPrompt(tone, musicData) {
    const { topGenres, popularityScore, topArtists, topTracks } = musicData
    
    const toneInstructions = {
      leve: "Crie um roast carinhoso e divertido, como um amigo brincando",
      debochado: "Seja sarc√°stico e elegante, com ironia sofisticada",
      quebrada: "Use g√≠rias brasileiras, seja direto e sem papas na l√≠ngua",
      exposed: "Seja psicol√≥gico e revelador, mas n√£o cruel",
      poetico: "Use linguagem art√≠stica e met√°foras musicais profundas"
    }

    return `
An√°lise do perfil musical:
- Top g√™neros: ${topGenres.map(g => g.genre).join(', ')}
- Artista principal: ${topArtists[0]?.name}
- Score de popularidade: ${popularityScore.score}/100 (${popularityScore.category})
- Top m√∫sica: ${topTracks[0]?.name}

Estilo solicitado: ${tone}
Instru√ß√£o: ${toneInstructions[tone]}

Crie um roast musical de no m√°ximo 280 caracteres, em portugu√™s brasileiro, que seja ${tone} sobre esse perfil musical. Seja criativo e espec√≠fico aos dados fornecidos.
    `.trim()
  }

  // Gerar roast com OpenAI
  async generateRoast(tone, musicData) {
    try {
      await this.rateLimitCheck()
      
      const prompt = this.buildPrompt(tone, musicData)
      
      const response = await this.openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content: "Voc√™ √© um cr√≠tico musical especialista em criar roasts divertidos sobre gosto musical. Seja criativo, espec√≠fico e mantenha o tom solicitado."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        max_tokens: 100,
        temperature: 0.8,
        presence_penalty: 0.1,
        frequency_penalty: 0.1
      })

      this.updateRateLimit()
      
      const roast = response.choices[0].message.content.trim()
      
      // Validar se o roast tem qualidade m√≠nima
      if (this.validateRoast(roast, musicData)) {
        return roast
      } else {
        throw new Error('Generated roast did not meet quality standards')
      }
      
    } catch (error) {
      console.error('OpenAI Generation Error:', error)
      throw error
    }
  }

  // Validar qualidade do roast gerado
  validateRoast(roast, musicData) {
    if (!roast || roast.length < 50) return false
    
    // Verificar se menciona pelo menos um elemento dos dados musicais
    const hasArtist = musicData.topArtists.some(artist => 
      roast.toLowerCase().includes(artist.name.toLowerCase())
    )
    const hasGenre = musicData.topGenres.some(genre => 
      roast.toLowerCase().includes(genre.genre.toLowerCase())
    )
    
    return hasArtist || hasGenre
  }

  // Rate limiting simples
  async rateLimitCheck() {
    const lastRequest = localStorage.getItem('openai_last_request')
    if (lastRequest) {
      const timeDiff = Date.now() - parseInt(lastRequest)
      if (timeDiff < this.rateLimitDelay) {
        await new Promise(resolve => setTimeout(resolve, this.rateLimitDelay - timeDiff))
      }
    }
  }

  updateRateLimit() {
    localStorage.setItem('openai_last_request', Date.now().toString())
  }

  // Verificar se tem API key configurada
  hasApiKey() {
    return !!import.meta.env.VITE_OPENAI_API_KEY && 
           import.meta.env.VITE_OPENAI_API_KEY !== 'sk-your-api-key-here'
  }
}

export default new OpenAIRoastService()
```

### **3. Servi√ßo H√≠brido (Local + OpenAI)**

```javascript
// src/services/hybridAiService.js
import aiRoastService from './aiRoastService.js'
import openaiService from './openaiService.js'

class HybridAIService {
  constructor() {
    this.preferOpenAI = true // Configur√°vel por usu√°rio
    this.fallbackEnabled = true
  }

  async generateRoast(tone, musicData, forceOpenAI = false) {
    const useOpenAI = (forceOpenAI || this.preferOpenAI) && openaiService.hasApiKey()
    
    if (useOpenAI) {
      try {
        console.log('ü§ñ Generating roast with OpenAI...')
        const openaiRoast = await openaiService.generateRoast(tone, musicData)
        
        // Log para analytics
        this.logUsage('openai', 'success', tone)
        
        return {
          roast: openaiRoast,
          source: 'OpenAI',
          enhanced: true
        }
      } catch (error) {
        console.warn('OpenAI failed:', error.message)
        this.logUsage('openai', 'error', tone, error.message)
        
        if (!this.fallbackEnabled) {
          throw error
        }
      }
    }

    // Fallback para IA local
    console.log('üß† Generating roast with local AI...')
    const localRoast = await aiRoastService.generateRoast(tone, musicData)
    
    this.logUsage('local', 'success', tone)
    
    return {
      roast: localRoast,
      source: 'Local AI',
      enhanced: false
    }
  }

  // Sistema de prefer√™ncias do usu√°rio
  setPreference(useOpenAI) {
    this.preferOpenAI = useOpenAI
    localStorage.setItem('ai_preference', useOpenAI ? 'openai' : 'local')
  }

  getPreference() {
    const saved = localStorage.getItem('ai_preference')
    return saved === 'openai'
  }

  // Analytics simples
  logUsage(source, status, tone, error = null) {
    const log = {
      timestamp: Date.now(),
      source,
      status,
      tone,
      error
    }
    
    const logs = JSON.parse(localStorage.getItem('ai_usage_logs') || '[]')
    logs.push(log)
    
    // Manter apenas √∫ltimos 100 logs
    if (logs.length > 100) {
      logs.splice(0, logs.length - 100)
    }
    
    localStorage.setItem('ai_usage_logs', JSON.stringify(logs))
  }

  // Estat√≠sticas de uso
  getUsageStats() {
    const logs = JSON.parse(localStorage.getItem('ai_usage_logs') || '[]')
    
    return {
      total: logs.length,
      openai: logs.filter(l => l.source === 'openai').length,
      local: logs.filter(l => l.source === 'local').length,
      errors: logs.filter(l => l.status === 'error').length,
      lastWeek: logs.filter(l => Date.now() - l.timestamp < 7 * 24 * 60 * 60 * 1000).length
    }
  }
}

export default new HybridAIService()
```

### **4. Atualizar Componente Principal**

```javascript
// src/components/SpotifyRoast.vue (atualiza√ß√£o do script)

import hybridAiService from '../services/hybridAiService.js'

// No m√©todo generateRoast:
const generateRoast = async () => {
  if (!musicAnalysis.value) {
    alert('Dados musicais ainda n√£o carregados. Tente novamente.')
    return
  }

  isGeneratingRoast.value = true
  roastResult.value = ''
  
  try {
    // Usar sistema h√≠brido
    const result = await hybridAiService.generateRoast(selectedTone.value, musicAnalysis.value)
    
    roastResult.value = result.roast
    roastSource.value = result.source
    roastEnhanced.value = result.enhanced
    
  } catch (error) {
    console.error('Error generating roast:', error)
    alert(`Erro ao gerar roast: ${error.message}`)
  } finally {
    isGeneratingRoast.value = false
  }
}
```

### **5. Interface de Configura√ß√£o**

```javascript
// Adicionar toggle no componente
<div class="ai-preference-toggle mb-3">
  <label class="form-check-label">
    <input 
      type="checkbox" 
      :checked="useOpenAI" 
      @change="toggleAIPreference"
      class="form-check-input"
    >
    ü§ñ Usar OpenAI (roasts mais criativos)
  </label>
  <small class="text-muted d-block">
    OpenAI gera roasts √∫nicos, IA local √© mais r√°pida
  </small>
</div>
```

## üîí Considera√ß√µes de Seguran√ßa

### **Para Produ√ß√£o:**
1. **Mover API key para backend**
2. **Implementar proxy endpoint**
3. **Rate limiting por usu√°rio**
4. **Modera√ß√£o de conte√∫do**

### **Backend Endpoint Exemplo:**
```javascript
// api/generate-roast.js (Vercel/Netlify Function)
export default async function handler(req, res) {
  const { tone, musicData } = req.body
  
  // Rate limiting por IP
  // Valida√ß√£o de dados
  // Chamada OpenAI
  // Modera√ß√£o de conte√∫do
  
  res.json({ roast, source: 'openai' })
}
```

## üìä Monitoramento

### **M√©tricas Importantes:**
- Custo por request (tokens)
- Taxa de erro OpenAI vs Local
- Satisfa√ß√£o do usu√°rio
- Tempo de resposta m√©dio

### **Dashboard Simples:**
```javascript
// Componente de analytics
const stats = hybridAiService.getUsageStats()
// Exibir estat√≠sticas de uso
```

## üéØ Benef√≠cios da Integra√ß√£o

1. **Qualidade Superior** - Roasts mais criativos e contextuais
2. **Fallback Robusto** - Sistema local como backup
3. **Flexibilidade** - Usu√°rio pode escolher
4. **Escalabilidade** - Preparado para crescimento
5. **Analytics** - Dados para otimiza√ß√£o

---

**Pr√≥ximo passo:** Implementar o `openaiService.js` e testar com uma API key de desenvolvimento!
